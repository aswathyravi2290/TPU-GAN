# -*- coding: utf-8 -*-
"""TPU_DCGAN_XLA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eb0zC06VdwdQTjYivu880tSR3dvDuvES
"""

# Commented out IPython magic to ensure Python compatibility.
import os, re, time, json
import PIL.Image, PIL.ImageFont, PIL.ImageDraw
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt
print("Tensorflow version " + tf.__version__)
# %load_ext tensorboard

import tensorflow as tf
import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import time
import random

from IPython import display

tf.__version__

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
tf.config.experimental_connect_to_cluster(resolver)
# This is the TPU initialization code that has to be at the beginning.
tf.tpu.experimental.initialize_tpu_system(resolver)
print("All devices: ", tf.config.list_logical_devices('TPU'))

try:
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
except ValueError:
  tpu = None
  gpus = tf.config.experimental.list_logical_devices("GPU")

if tpu:
  tf.config.experimental_connect_to_cluster(tpu)
  tf.tpu.experimental.initialize_tpu_system(tpu)
  strategy = tf.distribute.TPUStrategy(tpu) 
elif len(gpus) > 1:
  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])
elif len(gpus) == 1:
  strategy = tf.distribute.get_strategy()
else:
  strategy = tf.distribute.get_strategy()

print("Number of accelerators: ", strategy.num_replicas_in_sync)

def EnableXlaAcceleration():
  '''
  Enables compiler acceleration for linear algebra
  '''
  tf.config.optimizer.set_jit(True)
  print('Linear algebra acceleration enabled')
EnableXlaAcceleration()

IMAGE_SHAPE = (28,28,1) #@param
NOISE_DIM = 100 #@param {type:"integer"} 
GLOBAL_BATCH_SIZE = 128 #@param {type:"integer"}
EPOCHS =  30 #@param {type:"integer"}
NUM_EXAMPLES_TO_GENERATE = 16 #@param {type:"integer"}

CONFIG = {
    "BUFFER_SIZE":60000,
    "BATCH_SIZE_PER_REPLICA":int(GLOBAL_BATCH_SIZE / strategy.num_replicas_in_sync),
    "GLOBAL_BATCH_SIZE":GLOBAL_BATCH_SIZE,
    "REDUCTION_STRATEGY":tf.keras.losses.Reduction.NONE,
    "EPOCHS":EPOCHS,
    "NOISE_DIM":NOISE_DIM,
    "NUM_EXAMPLES_TO_GENERATE":NUM_EXAMPLES_TO_GENERATE,
    "NOISE_SHAPE":(NOISE_DIM,),
    #"IMAGE_SHAPE":(32,32,3)
    "IMAGE_SHAPE": IMAGE_SHAPE
}

GLOBAL_PARAM = {
    "RANDOM_SEED": 10
}

#Seed is used to have comparability between runs while maintaining random behavior!
random.seed(GLOBAL_PARAM["RANDOM_SEED"])
np.random.seed(seed=GLOBAL_PARAM["RANDOM_SEED"])

# You will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
latent_noise = tf.random.normal([CONFIG["NUM_EXAMPLES_TO_GENERATE"], CONFIG["NOISE_DIM"]])

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_images = train_images.reshape(train_images.shape[0], *CONFIG["IMAGE_SHAPE"]).astype('float32')
test_images = test_images.reshape(test_images.shape[0], *CONFIG["IMAGE_SHAPE"]).astype('float32')
train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]
test_images = (test_images - 127.5) / 127.5  # Normalize the images to [-1, 1]

print("Shape of train_images: {}".format(np.shape(train_images)))
print("Shape of test_images: {}".format(np.shape(test_images)))

# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(CONFIG["BUFFER_SIZE"]).batch(CONFIG["GLOBAL_BATCH_SIZE"],drop_remainder=True)
test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(CONFIG["BUFFER_SIZE"]).batch(CONFIG["GLOBAL_BATCH_SIZE"],drop_remainder=True)

#distribute
train_dataset_distributed = strategy.experimental_distribute_dataset(train_dataset)
test_dataset_distributed = strategy.experimental_distribute_dataset(test_dataset)

def Generator(inputShape = CONFIG["NOISE_SHAPE"]):
  # specify the input shape
  input_tensor = tf.keras.layers.Input(shape = inputShape)
 
  x = tf.keras.layers.Dense(7*7*256, use_bias=False)(input_tensor)
  x = tf.keras.layers.BatchNormalization()(x)
  x = tf.keras.layers.LeakyReLU()(x)

  x = tf.keras.layers.Reshape((7, 7, 256))(x)

  x = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)
  x = tf.keras.layers.BatchNormalization()(x)
  x = tf.keras.layers.LeakyReLU()(x)

  x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)
  x = tf.keras.layers.BatchNormalization()(x)
  x = tf.keras.layers.LeakyReLU()(x)

  x = tf.keras.layers.Conv2DTranspose(CONFIG["IMAGE_SHAPE"][-1], (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)

  # create the model
  model = tf.keras.Model(inputs=input_tensor, outputs=x, name = "Generator")

  return model

#Testcode
model = Generator()
model.summary()
tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=False, show_dtype=True, to_file="generator.png")

def generator_loss(fake_output):
  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=CONFIG["REDUCTION_STRATEGY"])
  loss = cross_entropy(tf.ones_like(fake_output), fake_output)
  loss = tf.reduce_sum(loss) *(1. / CONFIG["GLOBAL_BATCH_SIZE"])
  return loss

def Discriminator(inputShape = CONFIG["IMAGE_SHAPE"]):
  # specify the input shape
  input_tensor = tf.keras.layers.Input(shape = inputShape)
  x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(input_tensor)
  x = tf.keras.layers.LeakyReLU()(x)
  x = tf.keras.layers.Dropout(0.3)(x)

  x = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)
  x = tf.keras.layers.LeakyReLU()(x)
  x = tf.keras.layers.Dropout(0.3)(x)

  x = tf.keras.layers.Flatten()(x)
  x = tf.keras.layers.Dense(1)(x)

  # create the model
  model = tf.keras.Model(inputs=input_tensor, outputs=x, name = "Discriminator")

  return model

#Testcode
model = Discriminator()
model.summary()
tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=False, show_dtype=True, to_file="discriminator.png")

def discriminator_loss(real_output, fake_output):
  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=CONFIG["REDUCTION_STRATEGY"])
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  total_loss = tf.reduce_sum(total_loss) *(1. / CONFIG["GLOBAL_BATCH_SIZE"])
  return total_loss

class GAN(tf.keras.Model):
  def __init__(self, generator, discriminator, strategy = None):
    super(GAN, self).__init__()

    self.generator = generator
    self.discriminator = discriminator
    self.strategy = strategy

  def compile(self, generator_optimizer, discriminator_optimizer, generator_loss, discriminator_loss):
    super(GAN, self).compile()
    self.generator_optimizer = generator_optimizer
    self.discriminator_optimizer = discriminator_optimizer
    self.generator_loss = generator_loss
    self.discriminator_loss = discriminator_loss

  def call(self, batch):
    generated = self.generator(batch)
    discriminated = self.discriminator(generated)
    return tf.stack([generated, discriminated])

  @tf.function
  def train_step(self, batch):
    noise = tf.random.normal([CONFIG["BATCH_SIZE_PER_REPLICA"], CONFIG["NOISE_DIM"]])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = self.generator(noise, training=True)

      real_output = self.discriminator(batch, training=True)
      fake_output = self.discriminator(generated_images, training=True)

      gen_loss = self.generator_loss(fake_output)
      disc_loss = self.discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)

    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))
    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))
    return [gen_loss, disc_loss]

  @tf.function
  def test_step(self, batch):
    noise = tf.random.normal([CONFIG["BATCH_SIZE_PER_REPLICA"], CONFIG["NOISE_DIM"]])
    generated_images = self.generator(noise, training=False)

    real_output = self.discriminator(batch, training=False)
    fake_output = self.discriminator(generated_images, training=False)

    gen_loss = self.generator_loss(fake_output)
    disc_loss = self.discriminator_loss(real_output, fake_output)

    return [gen_loss, disc_loss]

  @tf.function
  def distributed_train_step(self, batch_train):
    ''' 
    per_replica_loss_vector:  vector of shape [per_replica-loss_gen1, per_replica-loss_gen2, per_replica-loss_disc1, per_replica-loss_disc1]
    reduced_loss_vector:      Vector of results of the different devices (for TPU 8)
    
    '''
    per_replica_loss_vector = self.strategy.run(self.train_step, args=(batch_train,))

    #reduce the result of the replicas for every loss value returned!
    reduced_loss_vector = []
    for per_replica_loss in per_replica_loss_vector:
      reduced_loss_vector.append(self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None))
    
    return reduced_loss_vector

  @tf.function
  def distributed_test_step(self, batch_test):
    ''' 
    per_replica_loss_vector:  vector of shape [per_replica-loss_gen1, per_replica-loss_gen2, per_replica-loss_disc1, per_replica-loss_disc1]
    reduced_loss_vector:      Vector of results of the different devices (for TPU 8)
    
    '''
    per_replica_loss_vector = self.strategy.run(self.test_step, args=(batch_test,))

    #reduce the result of the replicas for every loss value returned!
    reduced_loss_vector = []
    for per_replica_loss in per_replica_loss_vector:
      reduced_loss_vector.append(self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None))
    
    return reduced_loss_vector

  def train(self, train_dataset_distributed, test_dataset_distributed, epochs):
    start_training = time.time()
    for epoch in range(epochs):
      start_epoch = time.time()

      # initialize training parameter
      total_train_loss = [0., 0.]
      num_train_batches = 0

      for image_batch in train_dataset_distributed:
        total_train_loss = tf.math.add(total_train_loss, self.distributed_train_step(image_batch))
        num_train_batches += 1
      total_train_loss = total_train_loss / float(num_train_batches)

      if test_dataset_distributed is not None:
        # initialize training parameter
        total_test_loss = [0., 0.]
        num_test_batches = 0

        for image_batch in test_dataset_distributed:
          total_test_loss = tf.math.add(total_test_loss, self.distributed_test_step(image_batch))
          num_test_batches += 1
        total_test_loss = total_test_loss / float(num_test_batches)

      # Produce images for the GIF as you go
     # display.clear_output(wait=True)
     # self.generate_and_save_images(epoch + 1, latent_noise)

      print ('Total training time is {0:.3f} sec'.format(time.time()-start_training))
      print ('Time for epoch {0:5} is {1:.3f} sec'.format(epoch + 1, time.time()-start_epoch))
      print("Train:\nGen. Loss: {0:.6f} \nDisc. Loss: {1:.6f}".format(total_train_loss[0], total_train_loss[1]))
      if test_dataset_distributed is not None:
        print("Test:\nGen. Loss: {0:.6f} \nDisc. Loss: {1:.6f}".format(total_test_loss[0], total_test_loss[1]))

    # Generate after the final epoch
   # display.clear_output(wait=True)
   # self.generate_and_save_images(epochs, latent_noise)
    print ('Total training time is {0:.3f} sec'.format(time.time()-start_training))

with strategy.scope():
  ganModel = GAN(
      Generator(),
      Discriminator(),
      strategy
      )
ganModel.compile(
    generator_optimizer = tf.keras.optimizers.Adam(1e-4),
    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4),
    generator_loss = generator_loss, 
    discriminator_loss = discriminator_loss
)

ganModel.train(
    train_dataset_distributed=train_dataset_distributed,
    test_dataset_distributed = None,# test_dataset, 
    epochs = CONFIG["EPOCHS"])

# Display a single image using the epoch number
def display_image(epoch_no):
  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))

